Hello ChatGPT. Thank you for your help.

My docker-compose.yml file is as follows:

services:
  homeassistant:
    container_name: homeassistant
    image: ghcr.io/home-assistant/home-assistant:stable
    volumes:
      - ./home-assistant-config:/config
      - /etc/localtime:/etc/localtime:ro
    restart: unless-stopped
    privileged: true
    network_mode: host

  whisper:
    container_name: whisper
    image: rhasspy/wyoming-whisper
    command: --model small-int8
    ports:
      - "10300:10300"
    restart: unless-stopped

  piper:
    container_name: piper
    image: rhasspy/wyoming-piper
    command: --voice en_US-lessac-medium
    ports:
      - "10200:10200"
    restart: unless-stopped

  wyoming-satellite:
    container_name: wyoming-satellite
    image: sker65/wyoming-satellite:latest
    devices:
      - "/dev/snd:/dev/snd"
    volumes:
      - ./chatty-ww:/wake-word-models
    command: >
      --mic-command "arecord -D plughw:1,0 -f S16_LE -r 16000 -c 1"
      --snd-command "paplay --device=bluez_output.DA_1F_35_B9_D8_F5.1 -n Chatty"
      --uri tcp://0.0.0.0:10700
      --wake-word-name chatty
      --wake-command /wake-word-models/chatty.ppn
    ports:
      - "10700:10700"
    restart: unless-stopped

  localai:
    image: quay.io/go-skynet/local-ai:latest
    container_name: localai
    ports:
      - "8000:8000"
    volumes:
      - ./models:/models
    environment:
      - MODELS_PATH=/models
      - THREADS=4
      - DEBUG=true
      - DISABLE_MODEL_DOWNLOADS=true
      - DISABLE_AUTO_BUILD=true
    command: ["/usr/bin/local-ai", "--models-path", "/models"]
    restart: unless-stopped

I ran cd ~/ha-voice
nickspi5@raspberrypi1:~/ha-voice $ sudo docker compose down -v
[+] Running 6/6
 ✔ Container wyoming-satellite  Removed                                                                                 10.5s 
 ✔ Container localai            Removed                                                                                  0.9s 
 ✔ Container whisper            Removed                                                                                 10.5s 
 ✔ Container piper              Removed                                                                                  0.8s 
 ✔ Container homeassistant      Removed                                                                                  4.7s 
 ✔ Network ha-voice_default     Removed                                                                                  0.3s 
nickspi5@raspberrypi1:~/ha-voice $ sudo docker volume prune -f
Total reclaimed space: 0B
nickspi5@raspberrypi1:~/ha-voice $ sudo docker compose pull
[+] Pulling 12/12
 ✔ piper Pulled                                                                                                          3.2s 
 ✔ localai Pulled                                                                                                      121.7s 
   ✔ 0e25612b6db2 Already exists                                                                                         0.0s 
   ✔ fc07f3ef330c Pull complete                                                                                        107.8s 
   ✔ 4f4fb700ef54 Pull complete                                                                                        107.9s 
   ✔ 2366a4a7bde0 Pull complete                                                                                        115.0s 
   ✔ 2d487d0fddc4 Pull complete                                                                                        116.1s 
   ✔ bc55ae0d59ec Pull complete                                                                                        116.3s 
   ✔ 53f48d9d8bab Pull complete                                                                                        116.4s 
 ✔ wyoming-satellite Pulled                                                                                              3.2s 
 ✔ homeassistant Pulled                                                                                                  2.8s 
 ✔ whisper Pulled                                                                                                        3.2s 
nickspi5@raspberrypi1:~/ha-voice $ sudo docker compose up --build -d
[+] Running 6/6
 ✔ Network ha-voice_default     Created                                                                                  0.1s 
 ✔ Container whisper            Started                                                                                  5.4s 
 ✔ Container wyoming-satellite  Started                                                                                  5.8s 
 ✔ Container localai            Started                                                                                  6.0s 
 ✔ Container homeassistant      Started                                                                                  5.0s 
 ✔ Container piper              Started                                                                                  6.0s 
nickspi5@raspberrypi1:~/ha-voice $ curl http://localhost:8000/readyz
curl: (56) Recv failure: Connection reset by peer
nickspi5@raspberrypi1:~/ha-voice $ sudo docker logs -f localai
CPU info:
CPU: no AVX    found
CPU: no AVX2   found
CPU: no AVX512 found
7:10AM DBG Setting logging to debug
7:10AM INF Starting LocalAI using 4 threads, with models path: /models
7:10AM INF LocalAI version: v3.1.0 (6a650e68cb37487615887e27039f5b85fe0d418d)
7:10AM DBG CPU capabilities: [aes asimd asimddp asimdhp asimdrdm atomics cpuid crc32 dcpop evtstrm fp fphp lrcpc pmull sha1 sha2]
WARNING: failed to determine memory area for node: open /sys/devices/system/node/node0/hugepages: no such file or directory
WARNING: failed to read int from file: open /sys/class/drm/card0/device/numa_node: no such file or directory
WARNING: failed to read int from file: open /sys/class/drm/card1/device/numa_node: no such file or directory
WARNING: failed to determine memory area for node: open /sys/devices/system/node/node0/hugepages: no such file or directory
7:10AM DBG GPU count: 2
7:10AM DBG GPU: card #0 @1002000000.v3d
7:10AM DBG GPU: card #1 @axi:gpu
7:10AM WRN [startup] failed resolving model '/usr/bin/local-ai'
7:10AM ERR error installing models error="failed resolving model '/usr/bin/local-ai'"
7:10AM DBG GPU vendor gpuVendor=
7:10AM DBG guessDefaultsFromFile: NGPULayers set NGPULayers=99999999
7:10AM DBG Model file loaded: granite-embedding-107m-multilingual-f16.gguf architecture=bert bosTokenID=0 eosTokenID=2 modelName="Granite Embedding 107m Multilingual"
7:10AM DBG guessDefaultsFromFile: family not identified
7:10AM DBG guessDefaultsFromFile: NGPULayers set NGPULayers=99999999
7:10AM DBG Model file loaded: stable-diffusion-v1-5-pruned-emaonly-Q4_0.gguf architecture=diffusion bosTokenID=-1 eosTokenID=-1 modelName=
7:10AM DBG guessDefaultsFromFile: family not identified
7:10AM ERR guessDefaultsFromFile: panic while parsing gguf file
7:10AM DBG guessDefaultsFromFile: NGPULayers set NGPULayers=99999999
7:10AM DBG guessDefaultsFromFile: template already set name=gpt-4
7:10AM ERR config is not valid Name=tinyllama
7:10AM INF Preloading models from /models
7:10AM DBG Checking "stable-diffusion-v1-5-pruned-emaonly-Q4_0.gguf" exists and matches SHA
7:11AM DBG File "/models/stable-diffusion-v1-5-pruned-emaonly-Q4_0.gguf" already exists and matches the SHA. Skipping download

  Model name: stablediffusion                                                 



  curl http://localhost:8080/v1/images/generations  -H "Content-Type:         
  application/json"  -d '{ "prompt": "|", "step": 25, "size": "512x512" }'    


7:11AM DBG Checking "minicpm-v-2_6-Q4_K_M.gguf" exists and matches SHA
7:11AM INF Downloading "https://huggingface.co/openbmb/MiniCPM-V-2_6-gguf/resolve/main/ggml-model-Q4_K_M.gguf"
7:12AM INF Downloading /models/minicpm-v-2_6-Q4_K_M.gguf.partial: 32.0 KiB/118.6 MiB (0.01%) ETA: 162h52m50.135327525s
7:12AM INF Downloading /models/minicpm-v-2_6-Q4_K_M.gguf.partial: 13.4 MiB/118.6 MiB (5.65%) ETA: 22m53.792592945s
7:12AM INF Downloading /models/minicpm-v-2_6-Q4_K_M.gguf.partial: 24.3 MiB/118.6 MiB (10.24%) ETA: 12m45.149992809s
7:12AM INF Downloading /models/minicpm-v-2_6-Q4_K_M.gguf.partial: 31.3 MiB/118.6 MiB (13.18%) ETA: 10m9.645614695s
7:12AM INF Downloading /models/minicpm-v-2_6-Q4_K_M.gguf.partial: 44.6 MiB/118.6 MiB (18.78%) ETA: 7m1.943577441s
7:12AM INF Downloading /models/minicpm-v-2_6-Q4_K_M.gguf.partial: 53.2 MiB/118.6 MiB (22.41%) ETA: 5m55.131467227s
7:12AM INF Downloading /models/minicpm-v-2_6-Q4_K_M.gguf.partial: 62.3 MiB/118.6 MiB (26.26%) ETA: 5m2.253470314s
7:12AM INF Downloading /models/minicpm-v-2_6-Q4_K_M.gguf.partial: 68.2 MiB/118.6 MiB (28.74%) ETA: 4m39.213057576s
7:12AM INF Downloading /models/minicpm-v-2_6-Q4_K_M.gguf.partial: 71.6 MiB/118.6 MiB (30.17%) ETA: 4m32.228917662s
7:12AM INF Downloading /models/minicpm-v-2_6-Q4_K_M.gguf.partial: 79.9 MiB/118.6 MiB (33.67%) ETA: 4m1.638529266s
7:12AM INF Downloading /models/minicpm-v-2_6-Q4_K_M.gguf.partial: 87.9 MiB/118.6 MiB (37.06%) ETA: 3m36.881586722s
7:13AM INF Downloading /models/minicpm-v-2_6-Q4_K_M.gguf.partial: 99.0 MiB/118.6 MiB (41.72%) ETA: 3m5.334497795s
7:13AM INF Downloading /models/minicpm-v-2_6-Q4_K_M.gguf.partial: 106.6 MiB/118.6 MiB (44.93%) ETA: 2m48.764294841s
7:13AM INF Downloading /models/minicpm-v-2_6-Q4_K_M.gguf.partial: 115.7 MiB/118.6 MiB (48.76%) ETA: 2m29.932415897s
7:13AM INF File "/models/minicpm-v-2_6-Q4_K_M.gguf" downloaded and verified
7:13AM DBG Checking "minicpm-v-2_6-mmproj-f16.gguf" exists and matches SHA
7:13AM INF Downloading "https://huggingface.co/openbmb/MiniCPM-V-2_6-gguf/resolve/main/mmproj-model-f16.gguf"
7:13AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 6.5 MiB/996.0 MiB (0.33%) ETA: 12h29m32.31183519s
7:13AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 19.8 MiB/996.0 MiB (0.99%) ETA: 4h13m17.335055845s
7:13AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 29.6 MiB/996.0 MiB (1.48%) ETA: 2h54m30.59959244s
7:13AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 38.4 MiB/996.0 MiB (1.93%) ETA: 2h18m3.379028735s
7:13AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 50.6 MiB/996.0 MiB (2.54%) ETA: 1h47m15.978236312s
7:13AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 58.5 MiB/996.0 MiB (2.94%) ETA: 1h35m8.681111069s
7:13AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 64.6 MiB/996.0 MiB (3.24%) ETA: 1h28m23.467720242s
7:13AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 74.4 MiB/996.0 MiB (3.73%) ETA: 1h18m31.352316843s
7:13AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 89.3 MiB/996.0 MiB (4.48%) ETA: 1h6m40.787082571s
7:14AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 102.2 MiB/996.0 MiB (5.13%) ETA: 59m25.658295254s
7:14AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 120.6 MiB/996.0 MiB (6.05%) ETA: 51m10.437321969s
7:14AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 136.3 MiB/996.0 MiB (6.84%) ETA: 46m0.461859806s
7:14AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 153.9 MiB/996.0 MiB (7.73%) ETA: 41m21.529585039s
7:14AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 169.3 MiB/996.0 MiB (8.50%) ETA: 38m11.441884109s
7:14AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 186.4 MiB/996.0 MiB (9.36%) ETA: 35m10.072628501s
7:14AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 204.7 MiB/996.0 MiB (10.27%) ETA: 32m25.826643055s
7:14AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 221.5 MiB/996.0 MiB (11.12%) ETA: 30m21.181481838s
7:14AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 237.5 MiB/996.0 MiB (11.92%) ETA: 28m40.068586797s
7:14AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 255.3 MiB/996.0 MiB (12.82%) ETA: 26m57.563094578s
7:14AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 273.8 MiB/996.0 MiB (13.74%) ETA: 25m24.11102237s
7:14AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 292.2 MiB/996.0 MiB (14.67%) ETA: 24m1.574483274s
7:15AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 309.6 MiB/996.0 MiB (15.54%) ETA: 22m53.785523563s
7:15AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 329.1 MiB/996.0 MiB (16.52%) ETA: 21m43.194636922s
7:15AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 347.6 MiB/996.0 MiB (17.45%) ETA: 20m43.643407714s
7:15AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 359.5 MiB/996.0 MiB (18.04%) ETA: 20m16.963687287s
7:15AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 371.5 MiB/996.0 MiB (18.65%) ETA: 19m50.934390605s
7:15AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 384.8 MiB/996.0 MiB (19.32%) ETA: 19m20.979898537s
7:15AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 394.7 MiB/996.0 MiB (19.81%) ETA: 19m5.303999184s
7:15AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 407.4 MiB/996.0 MiB (20.45%) ETA: 18m40.170514749s
7:15AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 420.4 MiB/996.0 MiB (21.10%) ETA: 18m15.634587325s
7:15AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 432.3 MiB/996.0 MiB (21.70%) ETA: 17m55.415684038s
7:15AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 444.5 MiB/996.0 MiB (22.31%) ETA: 17m35.380827502s
7:15AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 456.7 MiB/996.0 MiB (22.93%) ETA: 17m15.972498237s
7:16AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 470.5 MiB/996.0 MiB (23.62%) ETA: 16m52.846905351s
7:16AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 484.4 MiB/996.0 MiB (24.31%) ETA: 16m30.648988945s
7:16AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 496.2 MiB/996.0 MiB (24.91%) ETA: 16m14.507325432s
7:16AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 509.6 MiB/996.0 MiB (25.58%) ETA: 15m55.100800307s
7:16AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 524.6 MiB/996.0 MiB (26.33%) ETA: 15m32.399534437s
7:16AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 537.9 MiB/996.0 MiB (27.00%) ETA: 15m14.520162864s
7:16AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 552.5 MiB/996.0 MiB (27.73%) ETA: 14m54.646838807s
7:16AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 566.8 MiB/996.0 MiB (28.45%) ETA: 14m36.084290332s
7:16AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 578.4 MiB/996.0 MiB (29.03%) ETA: 14m23.675979559s
7:16AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 590.1 MiB/996.0 MiB (29.62%) ETA: 14m11.554873499s
7:16AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 603.2 MiB/996.0 MiB (30.28%) ETA: 13m56.742198162s
7:16AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 618.1 MiB/996.0 MiB (31.03%) ETA: 13m39.035610021s
7:17AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 631.8 MiB/996.0 MiB (31.72%) ETA: 13m24.148503138s
7:17AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 643.0 MiB/996.0 MiB (32.28%) ETA: 13m14.077329887s
7:17AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 655.1 MiB/996.0 MiB (32.88%) ETA: 13m2.735165165s
7:17AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 668.4 MiB/996.0 MiB (33.55%) ETA: 12m49.363126956s
7:17AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 687.3 MiB/996.0 MiB (34.50%) ETA: 12m27.118179944s
7:17AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 705.9 MiB/996.0 MiB (35.44%) ETA: 12m6.10043542s
7:17AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 726.3 MiB/996.0 MiB (36.46%) ETA: 11m43.316484775s
7:17AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 747.6 MiB/996.0 MiB (37.53%) ETA: 11m20.098568326s
7:17AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 766.3 MiB/996.0 MiB (38.47%) ETA: 11m1.493194412s
7:17AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 783.0 MiB/996.0 MiB (39.30%) ETA: 10m46.347220109s
7:17AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 804.4 MiB/996.0 MiB (40.38%) ETA: 10m25.352006902s
7:17AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 821.1 MiB/996.0 MiB (41.22%) ETA: 10m11.194773652s
7:18AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 836.5 MiB/996.0 MiB (41.99%) ETA: 9m58.904257241s
7:18AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 847.6 MiB/996.0 MiB (42.55%) ETA: 9m52.178828664s
7:18AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 859.7 MiB/996.0 MiB (43.15%) ETA: 9m44.267055995s
7:18AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 874.7 MiB/996.0 MiB (43.91%) ETA: 9m33.043724858s
7:18AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 890.7 MiB/996.0 MiB (44.71%) ETA: 9m20.797345939s
7:18AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 909.7 MiB/996.0 MiB (45.66%) ETA: 9m5.629942099s
7:18AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 924.3 MiB/996.0 MiB (46.40%) ETA: 8m55.502950152s
7:18AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 936.3 MiB/996.0 MiB (47.00%) ETA: 8m48.354454417s
7:18AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 954.1 MiB/996.0 MiB (47.90%) ETA: 8m35.168749441s
7:18AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 971.5 MiB/996.0 MiB (48.77%) ETA: 8m22.728030338s
7:18AM INF Downloading /models/minicpm-v-2_6-mmproj-f16.gguf.partial: 987.9 MiB/996.0 MiB (49.59%) ETA: 8m11.561687549s
7:18AM INF File "/models/minicpm-v-2_6-mmproj-f16.gguf" downloaded and verified

  Model name: gpt-4o                                                          


7:18AM DBG Checking "voice-en-us-amy-low.tar.gz" exists and matches SHA
7:18AM DBG File "/models/voice-en-us-amy-low.tar.gz" already exists. Skipping download

  Model name: tts-1                                                           



  To test if this model works as expected, you can use the following curl     
  command:                                                                    
                                                                              
  curl http://localhost:8080/tts -H "Content-Type: application/json" -d '{    
  "model":"voice-en-us-amy-low", "input": "Hi, this is a test." }'            


7:18AM DBG Checking "silero-vad.onnx" exists and matches SHA
7:18AM DBG File "/models/silero-vad.onnx" already exists and matches the SHA. Skipping download

  Model name: silero-vad                                                      



  Model name: text-embedding-ada-002                                          



  You can test this model with curl like this:                                
                                                                              
  curl http://localhost:8080/embeddings -X POST -H "Content-Type:             
  application/json" -d '{ "input": "Your text string goes here", "model": "text-
  embedding-ada-002" }'                                                       


7:18AM DBG Checking "ggml-whisper-base.bin" exists and matches SHA
7:18AM DBG File "/models/ggml-whisper-base.bin" already exists and matches the SHA. Skipping download

  Model name: whisper-1                                                       



  ## example audio file                                                       
                                                                              
  wget --quiet --show-progress -O gb1.ogg                                     
  https://upload.wikimedia.org/wikipedia/commons/1/1f/George_W_Bush_Columbia_FINAL.ogg
                                                                              
  ## Send the example audio file to the transcriptions endpoint               
                                                                              
  curl http://localhost:8080/v1/audio/transcriptions  -H "Content-Type:       
  multipart/form-data"  -F file="@$PWD/gb1.ogg" -F model="whisper-1"          


7:18AM DBG Checking "jina-reranker-v1-tiny-en.f16.gguf" exists and matches SHA
7:18AM DBG File "/models/jina-reranker-v1-tiny-en.f16.gguf" already exists and matches the SHA. Skipping download

  Model name: jina-reranker-v1-base-en                                        



  You can test this model with curl like this:                                
                                                                              
  curl http://localhost:8080/v1/rerank  -H "Content-Type: application/json"  -d
  '{ "model": "jina-reranker-v1-base-en", "query": "Organic skincare products for
  sensitive skin", "documents": [ "Eco-friendly kitchenware for modern homes",
  "Biodegradable cleaning supplies for eco-conscious consumers", "Organic     
  cotton baby clothes for sensitive skin", "Natural organic skincare range for
  sensitive skin", "Tech gadgets for smart homes: 2024 edition", "Sustainable 
  gardening tools and compost solutions", "Sensitive skin-friendly facial     
  cleansers and toners", "Organic food wraps and storage solutions", "All-    
  natural pet food for dogs with allergies", "Yoga mats made from recycled    
  materials" ], "top_n": 3 }'                                                 


7:18AM DBG Checking "Hermes-3-Llama-3.2-3B-Q4_K_M.gguf" exists and matches SHA
7:19AM DBG File "/models/Hermes-3-Llama-3.2-3B-Q4_K_M.gguf" already exists and matches the SHA. Skipping download

  Model name: gpt-4                                                           


7:19AM DBG Model:  (config: {PredictionOptions:{BasicModelRequest:{Model:} Language: Translate:false N:0 TopP:0x4012ce9200 TopK:0x4012ce9208 Temperature:0x4012ce9210 Maxtokens:0x4012ce9240 Echo:false Batch:0 IgnoreEOS:false RepeatPenalty:0 RepeatLastN:0 Keep:0 FrequencyPenalty:0 PresencePenalty:0 TFZ:0x4012ce9238 TypicalP:0x4012ce9230 Seed:0x4012ce9250 NegativePrompt: RopeFreqBase:0 RopeFreqScale:0 NegativePromptScale:0 ClipSkip:0 Tokenizer:} Name: F16:0x4012ce91f8 Threads:0x4012ce91f0 Debug:0x4012ce9248 Roles:map[] Embeddings:0x4012ce9249 Backend: TemplateConfig:{Chat: ChatMessage: Completion: Edit: Functions: UseTokenizerTemplate:false JoinChatMessagesByCharacter:<nil> Multimodal: JinjaTemplate:false ReplyPrefix:} KnownUsecaseStrings:[FLAG_ANY] KnownUsecases:<nil> Pipeline:{TTS: LLM: Transcription: VAD:} PromptStrings:[] InputStrings:[] InputToken:[] functionCallString: functionCallNameString: ResponseFormat: ResponseFormatMap:map[] FunctionsConfig:{DisableNoAction:false GrammarConfig:{ParallelCalls:false DisableParallelNewLines:false MixedMode:false NoMixedFreeString:false NoGrammar:false Prefix: ExpectStringsAfterJSON:false PropOrder: SchemaType: GrammarTriggers:[]} NoActionFunctionName: NoActionDescriptionName: ResponseRegex:[] JSONRegexMatch:[] ArgumentRegex:[] ArgumentRegexKey: ArgumentRegexValue: ReplaceFunctionResults:[] ReplaceLLMResult:[] CaptureLLMResult:[] FunctionNameKey: FunctionArgumentsKey:} FeatureFlag:map[] LLMConfig:{SystemPrompt: TensorSplit: MainGPU: RMSNormEps:0 NGQA:0 PromptCachePath: PromptCacheAll:false PromptCacheRO:false MirostatETA:0x4012ce9228 MirostatTAU:0x4012ce9220 Mirostat:0x4012ce9218 NGPULayers:<nil> MMap:0x4012ce9248 MMlock:0x4012ce9249 LowVRAM:0x4012ce9249 Reranking:0x4012ce9249 Grammar: StopWords:[] Cutstrings:[] ExtractRegex:[] TrimSpace:[] TrimSuffix:[] ContextSize:0x4012ce9258 NUMA:false LoraAdapter: LoraBase: LoraAdapters:[] LoraScales:[] LoraScale:0 NoMulMatQ:false DraftModel: NDraft:0 Quantization: LoadFormat: GPUMemoryUtilization:0 TrustRemoteCode:false EnforceEager:false SwapSpace:0 MaxModelLen:0 TensorParallelSize:0 DisableLogStatus:false DType: LimitMMPerPrompt:{LimitImagePerPrompt:0 LimitVideoPerPrompt:0 LimitAudioPerPrompt:0} MMProj: FlashAttention:false NoKVOffloading:false CacheTypeK: CacheTypeV: RopeScaling: ModelType: YarnExtFactor:0 YarnAttnFactor:0 YarnBetaFast:0 YarnBetaSlow:0 CFGScale:0} Diffusers:{CUDA:false PipelineType: SchedulerType: EnableParameters: IMG2IMG:false ClipSkip:0 ClipModel: ClipSubFolder: ControlNet:} Step:0 GRPC:{Attempts:0 AttemptsSleepTime:0} TTSConfig:{Voice: AudioPath:} CUDA:false DownloadFiles:[] Description: Usage: Options:[]})
7:19AM DBG Model: gpt-4 (config: {PredictionOptions:{BasicModelRequest:{Model:Hermes-3-Llama-3.2-3B-Q4_K_M.gguf} Language: Translate:false N:0 TopP:0x400f79ecc0 TopK:0x400f79ecc8 Temperature:0x400f79ecd0 Maxtokens:0x400f79ed00 Echo:false Batch:0 IgnoreEOS:false RepeatPenalty:0 RepeatLastN:0 Keep:0 FrequencyPenalty:0 PresencePenalty:0 TFZ:0x400f79ecf8 TypicalP:0x400f79ecf0 Seed:0x400f79ed10 NegativePrompt: RopeFreqBase:0 RopeFreqScale:0 NegativePromptScale:0 ClipSkip:0 Tokenizer:} Name:gpt-4 F16:0x400f79ebb8 Threads:0x400f79ecb0 Debug:0x400f79ed08 Roles:map[] Embeddings:0x400f79ed09 Backend: TemplateConfig:{Chat:<|begin_of_text|><|start_header_id|>system<|end_header_id|>
You are a helpful assistant<|eot_id|><|start_header_id|>user<|end_header_id|>
{{.Input }}
<|start_header_id|>assistant<|end_header_id|>
 ChatMessage:<|start_header_id|>{{if eq .RoleName "assistant"}}assistant{{else if eq .RoleName "system"}}system{{else if eq .RoleName "tool"}}tool{{else if eq .RoleName "user"}}user{{end}}<|end_header_id|>
{{ if .FunctionCall -}}
{{ else if eq .RoleName "tool" -}}
The Function was executed and the response was:
{{ end -}}
{{ if .Content -}}
{{.Content -}}
{{ else if .FunctionCall -}}
{{ range .FunctionCall }}
[{{.FunctionCall.Name}}({{.FunctionCall.Arguments}})]
{{ end }}
{{ end -}}
<|eot_id|>
 Completion:{{.Input}}
 Edit: Functions:<|start_header_id|>system<|end_header_id|>
You are an expert in composing functions. You are given a question and a set of possible functions.
Based on the question, you will need to make one or more function/tool calls to achieve the purpose.
If none of the functions can be used, point it out. If the given question lacks the parameters required by the function, also point it out. You should only return the function call in tools call sections.
If you decide to invoke any of the function(s), you MUST put it in the format as follows:
[func_name1(params_name1=params_value1,params_name2=params_value2,...),func_name2(params_name1=params_value1,params_name2=params_value2,...)]
You SHOULD NOT include any other text in the response.
Here is a list of functions in JSON format that you can invoke.
{{toJson .Functions}}
<|eot_id|><|start_header_id|>user<|end_header_id|>
{{.Input}}
<|eot_id|><|start_header_id|>assistant<|end_header_id|>
 UseTokenizerTemplate:false JoinChatMessagesByCharacter:<nil> Multimodal: JinjaTemplate:false ReplyPrefix:} KnownUsecaseStrings:[FLAG_ANY FLAG_COMPLETION FLAG_CHAT] KnownUsecases:<nil> Pipeline:{TTS: LLM: Transcription: VAD:} PromptStrings:[] InputStrings:[] InputToken:[] functionCallString: functionCallNameString: ResponseFormat: ResponseFormatMap:map[] FunctionsConfig:{DisableNoAction:false GrammarConfig:{ParallelCalls:false DisableParallelNewLines:false MixedMode:false NoMixedFreeString:true NoGrammar:false Prefix: ExpectStringsAfterJSON:false PropOrder: SchemaType:llama3.1 GrammarTriggers:[]} NoActionFunctionName: NoActionDescriptionName: ResponseRegex:[<function=(?P<name>\w+)>(?P<arguments>.*)</function>] JSONRegexMatch:[] ArgumentRegex:[] ArgumentRegexKey: ArgumentRegexValue: ReplaceFunctionResults:[] ReplaceLLMResult:[] CaptureLLMResult:[] FunctionNameKey: FunctionArgumentsKey:} FeatureFlag:map[] LLMConfig:{SystemPrompt: TensorSplit: MainGPU: RMSNormEps:0 NGQA:0 PromptCachePath: PromptCacheAll:false PromptCacheRO:false MirostatETA:0x400f79ece8 MirostatTAU:0x400f79ece0 Mirostat:0x400f79ecd8 NGPULayers:0x4012ce8ff8 MMap:0x400f79ec9a MMlock:0x400f79ed09 LowVRAM:0x400f79ed09 Reranking:0x400f79ed09 Grammar: StopWords:[<|im_end|> <dummy32000> <|eot_id|> <|end_of_text|>] Cutstrings:[] ExtractRegex:[] TrimSpace:[] TrimSuffix:[] ContextSize:0x400f79eba8 NUMA:false LoraAdapter: LoraBase: LoraAdapters:[] LoraScales:[] LoraScale:0 NoMulMatQ:false DraftModel: NDraft:0 Quantization: LoadFormat: GPUMemoryUtilization:0 TrustRemoteCode:false EnforceEager:false SwapSpace:0 MaxModelLen:0 TensorParallelSize:0 DisableLogStatus:false DType: LimitMMPerPrompt:{LimitImagePerPrompt:0 LimitVideoPerPrompt:0 LimitAudioPerPrompt:0} MMProj: FlashAttention:false NoKVOffloading:false CacheTypeK: CacheTypeV: RopeScaling: ModelType: YarnExtFactor:0 YarnAttnFactor:0 YarnBetaFast:0 YarnBetaSlow:0 CFGScale:0} Diffusers:{CUDA:false PipelineType: SchedulerType: EnableParameters: IMG2IMG:false ClipSkip:0 ClipModel: ClipSubFolder: ControlNet:} Step:0 GRPC:{Attempts:0 AttemptsSleepTime:0} TTSConfig:{Voice: AudioPath:} CUDA:false DownloadFiles:[{Filename:Hermes-3-Llama-3.2-3B-Q4_K_M.gguf SHA256:2e220a14ba4328fee38cf36c2c068261560f999fadb5725ce5c6d977cb5126b5 URI:huggingface://bartowski/Hermes-3-Llama-3.2-3B-GGUF/Hermes-3-Llama-3.2-3B-Q4_K_M.gguf}] Description: Usage: Options:[]})
7:19AM DBG Model: gpt-4o (config: {PredictionOptions:{BasicModelRequest:{Model:minicpm-v-2_6-Q4_K_M.gguf} Language: Translate:false N:0 TopP:0x40101b6c00 TopK:0x40101b6c08 Temperature:0x40101b6c10 Maxtokens:0x40101b6c40 Echo:false Batch:0 IgnoreEOS:false RepeatPenalty:0 RepeatLastN:0 Keep:0 FrequencyPenalty:0 PresencePenalty:0 TFZ:0x40101b6c38 TypicalP:0x40101b6c30 Seed:0x40101b6c50 NegativePrompt: RopeFreqBase:0 RopeFreqScale:0 NegativePromptScale:0 ClipSkip:0 Tokenizer:} Name:gpt-4o F16:0x40101b6b80 Threads:0x40101b6bf0 Debug:0x40101b6c48 Roles:map[] Embeddings:0x40101b6c49 Backend: TemplateConfig:{Chat:{{.Input -}}
<|im_start|>assistant
 ChatMessage:<|im_start|>{{ .RoleName }}
{{ if .FunctionCall -}}
Function call:
{{ else if eq .RoleName "tool" -}}
Function response:
{{ end -}}
{{ if .Content -}}
{{.Content }}
{{ end -}}
{{ if .FunctionCall -}}
{{toJson .FunctionCall}}
{{ end -}}<|im_end|>
 Completion:{{.Input}}
 Edit: Functions:<|im_start|>system
You are a function calling AI model. You are provided with functions to execute. You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools:
{{range .Functions}}
{'type': 'function', 'function': {'name': '{{.Name}}', 'description': '{{.Description}}', 'parameters': {{toJson .Parameters}} }}
{{end}}
For each function call return a json object with function name and arguments
<|im_end|>
{{.Input -}}
<|im_start|>assistant
 UseTokenizerTemplate:false JoinChatMessagesByCharacter:<nil> Multimodal: JinjaTemplate:false ReplyPrefix:} KnownUsecaseStrings:[FLAG_ANY FLAG_CHAT FLAG_COMPLETION] KnownUsecases:<nil> Pipeline:{TTS: LLM: Transcription: VAD:} PromptStrings:[] InputStrings:[] InputToken:[] functionCallString: functionCallNameString: ResponseFormat: ResponseFormatMap:map[] FunctionsConfig:{DisableNoAction:false GrammarConfig:{ParallelCalls:false DisableParallelNewLines:false MixedMode:false NoMixedFreeString:false NoGrammar:false Prefix: ExpectStringsAfterJSON:false PropOrder: SchemaType: GrammarTriggers:[]} NoActionFunctionName: NoActionDescriptionName: ResponseRegex:[] JSONRegexMatch:[] ArgumentRegex:[] ArgumentRegexKey: ArgumentRegexValue: ReplaceFunctionResults:[] ReplaceLLMResult:[] CaptureLLMResult:[] FunctionNameKey: FunctionArgumentsKey:} FeatureFlag:map[] LLMConfig:{SystemPrompt: TensorSplit: MainGPU: RMSNormEps:0 NGQA:0 PromptCachePath: PromptCacheAll:false PromptCacheRO:false MirostatETA:0x40101b6c28 MirostatTAU:0x40101b6c20 Mirostat:0x40101b6c18 NGPULayers:<nil> MMap:0x40101b6b81 MMlock:0x40101b6c49 LowVRAM:0x40101b6c49 Reranking:0x40101b6c49 Grammar: StopWords:[<|im_end|> <dummy32000> </s> <|endoftext|>] Cutstrings:[] ExtractRegex:[] TrimSpace:[] TrimSuffix:[] ContextSize:0x40101b6b70 NUMA:false LoraAdapter: LoraBase: LoraAdapters:[] LoraScales:[] LoraScale:0 NoMulMatQ:false DraftModel: NDraft:0 Quantization: LoadFormat: GPUMemoryUtilization:0 TrustRemoteCode:false EnforceEager:false SwapSpace:0 MaxModelLen:0 TensorParallelSize:0 DisableLogStatus:false DType: LimitMMPerPrompt:{LimitImagePerPrompt:0 LimitVideoPerPrompt:0 LimitAudioPerPrompt:0} MMProj:minicpm-v-2_6-mmproj-f16.gguf FlashAttention:false NoKVOffloading:false CacheTypeK: CacheTypeV: RopeScaling: ModelType: YarnExtFactor:0 YarnAttnFactor:0 YarnBetaFast:0 YarnBetaSlow:0 CFGScale:0} Diffusers:{CUDA:false PipelineType: SchedulerType: EnableParameters: IMG2IMG:false ClipSkip:0 ClipModel: ClipSubFolder: ControlNet:} Step:0 GRPC:{Attempts:0 AttemptsSleepTime:0} TTSConfig:{Voice: AudioPath:} CUDA:false DownloadFiles:[{Filename:minicpm-v-2_6-Q4_K_M.gguf SHA256:3a4078d53b46f22989adbf998ce5a3fd090b6541f112d7e936eb4204a04100b1 URI:huggingface://openbmb/MiniCPM-V-2_6-gguf/ggml-model-Q4_K_M.gguf} {Filename:minicpm-v-2_6-mmproj-f16.gguf SHA256:4485f68a0f1aa404c391e788ea88ea653c100d8e98fe572698f701e5809711fd URI:huggingface://openbmb/MiniCPM-V-2_6-gguf/mmproj-model-f16.gguf}] Description: Usage: Options:[]})
7:19AM DBG Model: jina-reranker-v1-base-en (config: {PredictionOptions:{BasicModelRequest:{Model:jina-reranker-v1-tiny-en.f16.gguf} Language: Translate:false N:0 TopP:0x40101b7070 TopK:0x40101b7078 Temperature:0x40101b7080 Maxtokens:0x40101b70b0 Echo:false Batch:0 IgnoreEOS:false RepeatPenalty:0 RepeatLastN:0 Keep:0 FrequencyPenalty:0 PresencePenalty:0 TFZ:0x40101b70a8 TypicalP:0x40101b70a0 Seed:0x40101b70c0 NegativePrompt: RopeFreqBase:0 RopeFreqScale:0 NegativePromptScale:0 ClipSkip:0 Tokenizer:} Name:jina-reranker-v1-base-en F16:0x40101b7056 Threads:0x40101b7060 Debug:0x40101b70b8 Roles:map[] Embeddings:0x40101b70b9 Backend: TemplateConfig:{Chat: ChatMessage: Completion: Edit: Functions: UseTokenizerTemplate:false JoinChatMessagesByCharacter:<nil> Multimodal: JinjaTemplate:false ReplyPrefix:} KnownUsecaseStrings:[FLAG_ANY] KnownUsecases:<nil> Pipeline:{TTS: LLM: Transcription: VAD:} PromptStrings:[] InputStrings:[] InputToken:[] functionCallString: functionCallNameString: ResponseFormat: ResponseFormatMap:map[] FunctionsConfig:{DisableNoAction:false GrammarConfig:{ParallelCalls:false DisableParallelNewLines:false MixedMode:false NoMixedFreeString:false NoGrammar:false Prefix: ExpectStringsAfterJSON:false PropOrder: SchemaType: GrammarTriggers:[]} NoActionFunctionName: NoActionDescriptionName: ResponseRegex:[] JSONRegexMatch:[] ArgumentRegex:[] ArgumentRegexKey: ArgumentRegexValue: ReplaceFunctionResults:[] ReplaceLLMResult:[] CaptureLLMResult:[] FunctionNameKey: FunctionArgumentsKey:} FeatureFlag:map[] LLMConfig:{SystemPrompt: TensorSplit: MainGPU: RMSNormEps:0 NGQA:0 PromptCachePath: PromptCacheAll:false PromptCacheRO:false MirostatETA:0x40101b7098 MirostatTAU:0x40101b7090 Mirostat:0x40101b7088 NGPULayers:<nil> MMap:0x40101b70b8 MMlock:0x40101b70b9 LowVRAM:0x40101b70b9 Reranking:0x40101b7055 Grammar: StopWords:[] Cutstrings:[] ExtractRegex:[] TrimSpace:[] TrimSuffix:[] ContextSize:0x40101b70c8 NUMA:false LoraAdapter: LoraBase: LoraAdapters:[] LoraScales:[] LoraScale:0 NoMulMatQ:false DraftModel: NDraft:0 Quantization: LoadFormat: GPUMemoryUtilization:0 TrustRemoteCode:false EnforceEager:false SwapSpace:0 MaxModelLen:0 TensorParallelSize:0 DisableLogStatus:false DType: LimitMMPerPrompt:{LimitImagePerPrompt:0 LimitVideoPerPrompt:0 LimitAudioPerPrompt:0} MMProj: FlashAttention:false NoKVOffloading:false CacheTypeK: CacheTypeV: RopeScaling: ModelType: YarnExtFactor:0 YarnAttnFactor:0 YarnBetaFast:0 YarnBetaSlow:0 CFGScale:0} Diffusers:{CUDA:false PipelineType: SchedulerType: EnableParameters: IMG2IMG:false ClipSkip:0 ClipModel: ClipSubFolder: ControlNet:} Step:0 GRPC:{Attempts:0 AttemptsSleepTime:0} TTSConfig:{Voice: AudioPath:} CUDA:false DownloadFiles:[{Filename:jina-reranker-v1-tiny-en.f16.gguf SHA256:5f696cf0d0f3d347c4a279eee8270e5918554cdac0ed1f632f2619e4e8341407 URI:huggingface://mradermacher/jina-reranker-v1-tiny-en-GGUF/jina-reranker-v1-tiny-en.f16.gguf}] Description: Usage:You can test this model with curl like this:

curl http://localhost:8080/v1/rerank \
  -H "Content-Type: application/json" \
  -d '{
  "model": "jina-reranker-v1-base-en",
  "query": "Organic skincare products for sensitive skin",
  "documents": [
    "Eco-friendly kitchenware for modern homes",
    "Biodegradable cleaning supplies for eco-conscious consumers",
    "Organic cotton baby clothes for sensitive skin",
    "Natural organic skincare range for sensitive skin",
    "Tech gadgets for smart homes: 2024 edition",
    "Sustainable gardening tools and compost solutions",
    "Sensitive skin-friendly facial cleansers and toners",
    "Organic food wraps and storage solutions",
    "All-natural pet food for dogs with allergies",
    "Yoga mats made from recycled materials"
  ],
  "top_n": 3
}'
 Options:[]})
7:19AM DBG Model: silero-vad (config: {PredictionOptions:{BasicModelRequest:{Model:silero-vad.onnx} Language: Translate:false N:0 TopP:0x40101b6eb0 TopK:0x40101b6eb8 Temperature:0x40101b6ec0 Maxtokens:0x40101b6ef0 Echo:false Batch:0 IgnoreEOS:false RepeatPenalty:0 RepeatLastN:0 Keep:0 FrequencyPenalty:0 PresencePenalty:0 TFZ:0x40101b6ee8 TypicalP:0x40101b6ee0 Seed:0x40101b6f00 NegativePrompt: RopeFreqBase:0 RopeFreqScale:0 NegativePromptScale:0 ClipSkip:0 Tokenizer:} Name:silero-vad F16:0x40101b6ea8 Threads:0x40101b6ea0 Debug:0x40101b6ef8 Roles:map[] Embeddings:0x40101b6ef9 Backend:silero-vad TemplateConfig:{Chat: ChatMessage: Completion: Edit: Functions: UseTokenizerTemplate:false JoinChatMessagesByCharacter:<nil> Multimodal: JinjaTemplate:false ReplyPrefix:} KnownUsecaseStrings:[FLAG_ANY FLAG_VAD] KnownUsecases:<nil> Pipeline:{TTS: LLM: Transcription: VAD:} PromptStrings:[] InputStrings:[] InputToken:[] functionCallString: functionCallNameString: ResponseFormat: ResponseFormatMap:map[] FunctionsConfig:{DisableNoAction:false GrammarConfig:{ParallelCalls:false DisableParallelNewLines:false MixedMode:false NoMixedFreeString:false NoGrammar:false Prefix: ExpectStringsAfterJSON:false PropOrder: SchemaType: GrammarTriggers:[]} NoActionFunctionName: NoActionDescriptionName: ResponseRegex:[] JSONRegexMatch:[] ArgumentRegex:[] ArgumentRegexKey: ArgumentRegexValue: ReplaceFunctionResults:[] ReplaceLLMResult:[] CaptureLLMResult:[] FunctionNameKey: FunctionArgumentsKey:} FeatureFlag:map[] LLMConfig:{SystemPrompt: TensorSplit: MainGPU: RMSNormEps:0 NGQA:0 PromptCachePath: PromptCacheAll:false PromptCacheRO:false MirostatETA:0x40101b6ed8 MirostatTAU:0x40101b6ed0 Mirostat:0x40101b6ec8 NGPULayers:<nil> MMap:0x40101b6ef8 MMlock:0x40101b6ef9 LowVRAM:0x40101b6ef9 Reranking:0x40101b6ef9 Grammar: StopWords:[] Cutstrings:[] ExtractRegex:[] TrimSpace:[] TrimSuffix:[] ContextSize:0x40101b6f08 NUMA:false LoraAdapter: LoraBase: LoraAdapters:[] LoraScales:[] LoraScale:0 NoMulMatQ:false DraftModel: NDraft:0 Quantization: LoadFormat: GPUMemoryUtilization:0 TrustRemoteCode:false EnforceEager:false SwapSpace:0 MaxModelLen:0 TensorParallelSize:0 DisableLogStatus:false DType: LimitMMPerPrompt:{LimitImagePerPrompt:0 LimitVideoPerPrompt:0 LimitAudioPerPrompt:0} MMProj: FlashAttention:false NoKVOffloading:false CacheTypeK: CacheTypeV: RopeScaling: ModelType: YarnExtFactor:0 YarnAttnFactor:0 YarnBetaFast:0 YarnBetaSlow:0 CFGScale:0} Diffusers:{CUDA:false PipelineType: SchedulerType: EnableParameters: IMG2IMG:false ClipSkip:0 ClipModel: ClipSubFolder: ControlNet:} Step:0 GRPC:{Attempts:0 AttemptsSleepTime:0} TTSConfig:{Voice: AudioPath:} CUDA:false DownloadFiles:[{Filename:silero-vad.onnx SHA256:a4a068cd6cf1ea8355b84327595838ca748ec29a25bc91fc82e6c299ccdc5808 URI:https://huggingface.co/onnx-community/silero-vad/resolve/main/onnx/model.onnx}] Description: Usage: Options:[]})
7:19AM DBG Model: stablediffusion (config: {PredictionOptions:{BasicModelRequest:{Model:stable-diffusion-v1-5-pruned-emaonly-Q4_0.gguf} Language: Translate:false N:0 TopP:0x40100c6458 TopK:0x40100c6460 Temperature:0x40100c6468 Maxtokens:0x40100c6498 Echo:false Batch:0 IgnoreEOS:false RepeatPenalty:0 RepeatLastN:0 Keep:0 FrequencyPenalty:0 PresencePenalty:0 TFZ:0x40100c6490 TypicalP:0x40100c6488 Seed:0x40100c64a8 NegativePrompt: RopeFreqBase:0 RopeFreqScale:0 NegativePromptScale:0 ClipSkip:0 Tokenizer:} Name:stablediffusion F16:0x40100c6450 Threads:0x40100c6448 Debug:0x40100c64a0 Roles:map[] Embeddings:0x40100c64a1 Backend:stablediffusion-ggml TemplateConfig:{Chat: ChatMessage: Completion: Edit: Functions: UseTokenizerTemplate:false JoinChatMessagesByCharacter:<nil> Multimodal: JinjaTemplate:false ReplyPrefix:} KnownUsecaseStrings:[FLAG_IMAGE FLAG_ANY] KnownUsecases:<nil> Pipeline:{TTS: LLM: Transcription: VAD:} PromptStrings:[] InputStrings:[] InputToken:[] functionCallString: functionCallNameString: ResponseFormat: ResponseFormatMap:map[] FunctionsConfig:{DisableNoAction:false GrammarConfig:{ParallelCalls:false DisableParallelNewLines:false MixedMode:false NoMixedFreeString:false NoGrammar:false Prefix: ExpectStringsAfterJSON:false PropOrder: SchemaType: GrammarTriggers:[]} NoActionFunctionName: NoActionDescriptionName: ResponseRegex:[] JSONRegexMatch:[] ArgumentRegex:[] ArgumentRegexKey: ArgumentRegexValue: ReplaceFunctionResults:[] ReplaceLLMResult:[] CaptureLLMResult:[] FunctionNameKey: FunctionArgumentsKey:} FeatureFlag:map[] LLMConfig:{SystemPrompt: TensorSplit: MainGPU: RMSNormEps:0 NGQA:0 PromptCachePath: PromptCacheAll:false PromptCacheRO:false MirostatETA:0x40100c6480 MirostatTAU:0x40100c6478 Mirostat:0x40100c6470 NGPULayers:0x40101b66f0 MMap:0x40100c64a0 MMlock:0x40100c64a1 LowVRAM:0x40100c64a1 Reranking:0x40100c64a1 Grammar: StopWords:[] Cutstrings:[] ExtractRegex:[] TrimSpace:[] TrimSuffix:[] ContextSize:0x401012d3d0 NUMA:false LoraAdapter: LoraBase: LoraAdapters:[] LoraScales:[] LoraScale:0 NoMulMatQ:false DraftModel: NDraft:0 Quantization: LoadFormat: GPUMemoryUtilization:0 TrustRemoteCode:false EnforceEager:false SwapSpace:0 MaxModelLen:0 TensorParallelSize:0 DisableLogStatus:false DType: LimitMMPerPrompt:{LimitImagePerPrompt:0 LimitVideoPerPrompt:0 LimitAudioPerPrompt:0} MMProj: FlashAttention:false NoKVOffloading:false CacheTypeK: CacheTypeV: RopeScaling: ModelType: YarnExtFactor:0 YarnAttnFactor:0 YarnBetaFast:0 YarnBetaSlow:0 CFGScale:4.5} Diffusers:{CUDA:false PipelineType: SchedulerType: EnableParameters: IMG2IMG:false ClipSkip:0 ClipModel: ClipSubFolder: ControlNet:} Step:25 GRPC:{Attempts:0 AttemptsSleepTime:0} TTSConfig:{Voice: AudioPath:} CUDA:false DownloadFiles:[{Filename:stable-diffusion-v1-5-pruned-emaonly-Q4_0.gguf SHA256:b8944e9fe0b69b36ae1b5bb0185b3a7b8ef14347fe0fa9af6c64c4829022261f URI:huggingface://second-state/stable-diffusion-v1-5-GGUF/stable-diffusion-v1-5-pruned-emaonly-Q4_0.gguf}] Description: Usage:curl http://localhost:8080/v1/images/generations \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "<positive prompt>|<negative prompt>",
    "step": 25,
    "size": "512x512"
  }' Options:[sampler:euler]})
7:19AM DBG Model: text-embedding-ada-002 (config: {PredictionOptions:{BasicModelRequest:{Model:granite-embedding-107m-multilingual-f16.gguf} Language: Translate:false N:0 TopP:0x400d926cc0 TopK:0x400d926cc8 Temperature:0x400d926cd0 Maxtokens:0x400d926d00 Echo:false Batch:0 IgnoreEOS:false RepeatPenalty:0 RepeatLastN:0 Keep:0 FrequencyPenalty:0 PresencePenalty:0 TFZ:0x400d926cf8 TypicalP:0x400d926cf0 Seed:0x400d926d10 NegativePrompt: RopeFreqBase:0 RopeFreqScale:0 NegativePromptScale:0 ClipSkip:0 Tokenizer:} Name:text-embedding-ada-002 F16:0x400d926cb8 Threads:0x400d926cb0 Debug:0x400d926d08 Roles:map[] Embeddings:0x400d926ba0 Backend: TemplateConfig:{Chat: ChatMessage: Completion: Edit: Functions: UseTokenizerTemplate:false JoinChatMessagesByCharacter:<nil> Multimodal: JinjaTemplate:false ReplyPrefix:} KnownUsecaseStrings:[FLAG_ANY FLAG_EMBEDDINGS] KnownUsecases:<nil> Pipeline:{TTS: LLM: Transcription: VAD:} PromptStrings:[] InputStrings:[] InputToken:[] functionCallString: functionCallNameString: ResponseFormat: ResponseFormatMap:map[] FunctionsConfig:{DisableNoAction:false GrammarConfig:{ParallelCalls:false DisableParallelNewLines:false MixedMode:false NoMixedFreeString:false NoGrammar:false Prefix: ExpectStringsAfterJSON:false PropOrder: SchemaType: GrammarTriggers:[]} NoActionFunctionName: NoActionDescriptionName: ResponseRegex:[] JSONRegexMatch:[] ArgumentRegex:[] ArgumentRegexKey: ArgumentRegexValue: ReplaceFunctionResults:[] ReplaceLLMResult:[] CaptureLLMResult:[] FunctionNameKey: FunctionArgumentsKey:} FeatureFlag:map[] LLMConfig:{SystemPrompt: TensorSplit: MainGPU: RMSNormEps:0 NGQA:0 PromptCachePath: PromptCacheAll:false PromptCacheRO:false MirostatETA:0x400d926ce8 MirostatTAU:0x400d926ce0 Mirostat:0x400d926cd8 NGPULayers:0x40100b9f20 MMap:0x400d926d08 MMlock:0x400d926d09 LowVRAM:0x400d926d09 Reranking:0x400d926d09 Grammar: StopWords:[] Cutstrings:[] ExtractRegex:[] TrimSpace:[] TrimSuffix:[] ContextSize:0x40100b9e88 NUMA:false LoraAdapter: LoraBase: LoraAdapters:[] LoraScales:[] LoraScale:0 NoMulMatQ:false DraftModel: NDraft:0 Quantization: LoadFormat: GPUMemoryUtilization:0 TrustRemoteCode:false EnforceEager:false SwapSpace:0 MaxModelLen:0 TensorParallelSize:0 DisableLogStatus:false DType: LimitMMPerPrompt:{LimitImagePerPrompt:0 LimitVideoPerPrompt:0 LimitAudioPerPrompt:0} MMProj: FlashAttention:false NoKVOffloading:false CacheTypeK: CacheTypeV: RopeScaling: ModelType: YarnExtFactor:0 YarnAttnFactor:0 YarnBetaFast:0 YarnBetaSlow:0 CFGScale:0} Diffusers:{CUDA:false PipelineType: SchedulerType: EnableParameters: IMG2IMG:false ClipSkip:0 ClipModel: ClipSubFolder: ControlNet:} Step:0 GRPC:{Attempts:0 AttemptsSleepTime:0} TTSConfig:{Voice: AudioPath:} CUDA:false DownloadFiles:[] Description: Usage:You can test this model with curl like this:

curl http://localhost:8080/embeddings -X POST -H "Content-Type: application/json" -d '{
  "input": "Your text string goes here",
  "model": "text-embedding-ada-002"
}' Options:[]})
7:19AM DBG Model: tts-1 (config: {PredictionOptions:{BasicModelRequest:{Model:en-us-amy-low.onnx} Language: Translate:false N:0 TopP:0x40101b6d40 TopK:0x40101b6d48 Temperature:0x40101b6d50 Maxtokens:0x40101b6d80 Echo:false Batch:0 IgnoreEOS:false RepeatPenalty:0 RepeatLastN:0 Keep:0 FrequencyPenalty:0 PresencePenalty:0 TFZ:0x40101b6d78 TypicalP:0x40101b6d70 Seed:0x40101b6d90 NegativePrompt: RopeFreqBase:0 RopeFreqScale:0 NegativePromptScale:0 ClipSkip:0 Tokenizer:} Name:tts-1 F16:0x40101b6d38 Threads:0x40101b6d30 Debug:0x40101b6d88 Roles:map[] Embeddings:0x40101b6d89 Backend: TemplateConfig:{Chat: ChatMessage: Completion: Edit: Functions: UseTokenizerTemplate:false JoinChatMessagesByCharacter:<nil> Multimodal: JinjaTemplate:false ReplyPrefix:} KnownUsecaseStrings:[FLAG_ANY] KnownUsecases:<nil> Pipeline:{TTS: LLM: Transcription: VAD:} PromptStrings:[] InputStrings:[] InputToken:[] functionCallString: functionCallNameString: ResponseFormat: ResponseFormatMap:map[] FunctionsConfig:{DisableNoAction:false GrammarConfig:{ParallelCalls:false DisableParallelNewLines:false MixedMode:false NoMixedFreeString:false NoGrammar:false Prefix: ExpectStringsAfterJSON:false PropOrder: SchemaType: GrammarTriggers:[]} NoActionFunctionName: NoActionDescriptionName: ResponseRegex:[] JSONRegexMatch:[] ArgumentRegex:[] ArgumentRegexKey: ArgumentRegexValue: ReplaceFunctionResults:[] ReplaceLLMResult:[] CaptureLLMResult:[] FunctionNameKey: FunctionArgumentsKey:} FeatureFlag:map[] LLMConfig:{SystemPrompt: TensorSplit: MainGPU: RMSNormEps:0 NGQA:0 PromptCachePath: PromptCacheAll:false PromptCacheRO:false MirostatETA:0x40101b6d68 MirostatTAU:0x40101b6d60 Mirostat:0x40101b6d58 NGPULayers:<nil> MMap:0x40101b6d88 MMlock:0x40101b6d89 LowVRAM:0x40101b6d89 Reranking:0x40101b6d89 Grammar: StopWords:[] Cutstrings:[] ExtractRegex:[] TrimSpace:[] TrimSuffix:[] ContextSize:0x40101b6d98 NUMA:false LoraAdapter: LoraBase: LoraAdapters:[] LoraScales:[] LoraScale:0 NoMulMatQ:false DraftModel: NDraft:0 Quantization: LoadFormat: GPUMemoryUtilization:0 TrustRemoteCode:false EnforceEager:false SwapSpace:0 MaxModelLen:0 TensorParallelSize:0 DisableLogStatus:false DType: LimitMMPerPrompt:{LimitImagePerPrompt:0 LimitVideoPerPrompt:0 LimitAudioPerPrompt:0} MMProj: FlashAttention:false NoKVOffloading:false CacheTypeK: CacheTypeV: RopeScaling: ModelType: YarnExtFactor:0 YarnAttnFactor:0 YarnBetaFast:0 YarnBetaSlow:0 CFGScale:0} Diffusers:{CUDA:false PipelineType: SchedulerType: EnableParameters: IMG2IMG:false ClipSkip:0 ClipModel: ClipSubFolder: ControlNet:} Step:0 GRPC:{Attempts:0 AttemptsSleepTime:0} TTSConfig:{Voice: AudioPath:} CUDA:false DownloadFiles:[{Filename:voice-en-us-amy-low.tar.gz SHA256: URI:https://github.com/rhasspy/piper/releases/download/v0.0.2/voice-en-us-amy-low.tar.gz}] Description: Usage:To test if this model works as expected, you can use the following curl command:

curl http://localhost:8080/tts -H "Content-Type: application/json" -d '{
  "model":"voice-en-us-amy-low",
  "input": "Hi, this is a test."
}' Options:[]})
7:19AM DBG Model: whisper-1 (config: {PredictionOptions:{BasicModelRequest:{Model:ggml-whisper-base.bin} Language: Translate:false N:0 TopP:0x40100c6250 TopK:0x40100c6258 Temperature:0x40100c6260 Maxtokens:0x40100c6290 Echo:false Batch:0 IgnoreEOS:false RepeatPenalty:0 RepeatLastN:0 Keep:0 FrequencyPenalty:0 PresencePenalty:0 TFZ:0x40100c6288 TypicalP:0x40100c6280 Seed:0x40100c62a0 NegativePrompt: RopeFreqBase:0 RopeFreqScale:0 NegativePromptScale:0 ClipSkip:0 Tokenizer:} Name:whisper-1 F16:0x40100c6248 Threads:0x40100c6240 Debug:0x40100c6298 Roles:map[] Embeddings:0x40100c6299 Backend:whisper TemplateConfig:{Chat: ChatMessage: Completion: Edit: Functions: UseTokenizerTemplate:false JoinChatMessagesByCharacter:<nil> Multimodal: JinjaTemplate:false ReplyPrefix:} KnownUsecaseStrings:[FLAG_TRANSCRIPT FLAG_ANY] KnownUsecases:<nil> Pipeline:{TTS: LLM: Transcription: VAD:} PromptStrings:[] InputStrings:[] InputToken:[] functionCallString: functionCallNameString: ResponseFormat: ResponseFormatMap:map[] FunctionsConfig:{DisableNoAction:false GrammarConfig:{ParallelCalls:false DisableParallelNewLines:false MixedMode:false NoMixedFreeString:false NoGrammar:false Prefix: ExpectStringsAfterJSON:false PropOrder: SchemaType: GrammarTriggers:[]} NoActionFunctionName: NoActionDescriptionName: ResponseRegex:[] JSONRegexMatch:[] ArgumentRegex:[] ArgumentRegexKey: ArgumentRegexValue: ReplaceFunctionResults:[] ReplaceLLMResult:[] CaptureLLMResult:[] FunctionNameKey: FunctionArgumentsKey:} FeatureFlag:map[] LLMConfig:{SystemPrompt: TensorSplit: MainGPU: RMSNormEps:0 NGQA:0 PromptCachePath: PromptCacheAll:false PromptCacheRO:false MirostatETA:0x40100c6278 MirostatTAU:0x40100c6270 Mirostat:0x40100c6268 NGPULayers:<nil> MMap:0x40100c6298 MMlock:0x40100c6299 LowVRAM:0x40100c6299 Reranking:0x40100c6299 Grammar: StopWords:[] Cutstrings:[] ExtractRegex:[] TrimSpace:[] TrimSuffix:[] ContextSize:0x40100c62a8 NUMA:false LoraAdapter: LoraBase: LoraAdapters:[] LoraScales:[] LoraScale:0 NoMulMatQ:false DraftModel: NDraft:0 Quantization: LoadFormat: GPUMemoryUtilization:0 TrustRemoteCode:false EnforceEager:false SwapSpace:0 MaxModelLen:0 TensorParallelSize:0 DisableLogStatus:false DType: LimitMMPerPrompt:{LimitImagePerPrompt:0 LimitVideoPerPrompt:0 LimitAudioPerPrompt:0} MMProj: FlashAttention:false NoKVOffloading:false CacheTypeK: CacheTypeV: RopeScaling: ModelType: YarnExtFactor:0 YarnAttnFactor:0 YarnBetaFast:0 YarnBetaSlow:0 CFGScale:0} Diffusers:{CUDA:false PipelineType: SchedulerType: EnableParameters: IMG2IMG:false ClipSkip:0 ClipModel: ClipSubFolder: ControlNet:} Step:0 GRPC:{Attempts:0 AttemptsSleepTime:0} TTSConfig:{Voice: AudioPath:} CUDA:false DownloadFiles:[{Filename:ggml-whisper-base.bin SHA256:60ed5bc3dd14eea856493d334349b405782ddcaf0028d4b5df4088345fba2efe URI:https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin}] Description: Usage:## example audio file
wget --quiet --show-progress -O gb1.ogg https://upload.wikimedia.org/wikipedia/commons/1/1f/George_W_Bush_Columbia_FINAL.ogg

## Send the example audio file to the transcriptions endpoint
curl http://localhost:8080/v1/audio/transcriptions \
     -H "Content-Type: multipart/form-data" \
     -F file="@$PWD/gb1.ogg" -F model="whisper-1"
 Options:[]})
7:19AM DBG Extracting backend assets files to /tmp/localai/backend_data
7:19AM DBG processing api keys runtime update
7:19AM DBG processing external_backends.json
7:19AM DBG external backends loaded from external_backends.json
7:19AM INF core/startup process completed!
7:19AM DBG No configuration file found at /tmp/localai/upload/uploadedFiles.json
7:19AM DBG No configuration file found at /tmp/localai/config/assistants.json
7:19AM DBG No configuration file found at /tmp/localai/config/assistantsFile.json
7:19AM DBG GPU vendor gpuVendor=
7:19AM INF LocalAI API is listening! Please connect to the endpoint for API documentation. endpoint=http://0.0.0.0:8080
7:19AM INF Success ip=127.0.0.1 latency=11.229971ms method=GET status=200 url=/readyz
7:20AM INF Success ip=127.0.0.1 latency="47.512µs" method=GET status=200 url=/readyz
7:21AM INF Success ip=127.0.0.1 latency="18.331µs" method=GET status=200 url=/readyz

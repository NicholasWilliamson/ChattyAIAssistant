models:
  - name: tinyllama
    backend: llama-cpp
    path: /models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf
    parameters:
      n_ctx: 2048
      n_threads: 4
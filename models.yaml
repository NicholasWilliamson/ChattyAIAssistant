models:
  - name: tinyllama
    backend: llama-cpp
    path: /models/tinyllama.gguf
    parameters:
      n_ctx: 2048
      n_threads: 4
How to Download Hermes 3 LLaMA 3.2 Q4_K_M
From your Pi 5 (within your ha-voice folder):

bash
Copy
Edit
cd models
wget https://huggingface.co/TheBloke/Hermes-3-Llama-3.2-8B-GGUF/resolve/main/Hermes-3-Llama-3.2-8B-Q4_K_M.gguf
Then create the matching YAML file:

ðŸ§¾ Hermes-3-Llama-3.2-8B-Q4_K_M.yaml
yaml
Copy
Edit
name: hermes
backend: llama-cpp
parameters:
  model: /models/Hermes-3-Llama-3.2-8B-Q4_K_M.gguf
  temperature: 0.7
  top_k: 50
  top_p: 0.9
  n_predict: 400
  stopwords:
    - "<|im_end|>"
    - "<|endoftext|>"
  repeat_penalty: 1.1
  threads: 4
  batch: 64
  context_size: 4096
  f16: true
  gpu_layers: 35  # For Pi 5 + Vulkan or CUDA if supported
You can name it:

bash
Copy
Edit
/models/hermes.yaml
ðŸ”„ Reload LocalAI
After saving the model and YAML:

bash
Copy
Edit
sudo docker compose down
sudo docker compose up -d
Then test it:

bash
Copy
Edit
curl -s http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "hermes",
    "messages": [
      {"role": "user", "content": "Hey Chatty, what's the best way to cook a steak?"}
    ]
  }' | jq
ðŸ§  Optional: Make Hermes Default
Edit your models.yaml and set:

yaml
Copy
Edit
default_model: hermes
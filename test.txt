

First, let's check what model your Chatty AI is actually using:
bashgrep -n "whisper\|Whisper\|faster_whisper\|WhisperModel" /home/nickspi5/Chatty_AI/chatty_ai.py | head -20

2. Check Current Whisper Configuration
bashgrep -A5 -B5 "WhisperModel\|model_size\|compute_type" /home/nickspi5/Chatty_AI/chatty_ai.py

3. Optimize LLM with More Threads
Your Pi 5 has 4 cores. Let's check if we're using all of them:
bashgrep -n "n_threads\|Llama(" /home/nickspi5/Chatty_AI/chatty_ai.py

4. Check Audio Recording Duration
Long audio files take longer to transcribe. Let's see what the test audio file looks like:
bash# Check audio file duration
ffprobe -i /home/nickspi5/Chatty_AI/test_audio.wav 2>&1 | grep Duration
If ffprobe isn't installed:
bashls -la /home/nickspi5/Chatty_AI/test_audio.wav





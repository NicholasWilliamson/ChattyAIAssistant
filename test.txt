

Thank you, Claude,

I ran: nickspi5@raspberrypi:~ $ grep -A20 "def process_user_input" /home/nickspi5/Chatty_AI/chatty_ai.py
    def process_user_input(self, text):
        """Process user input - Same as original"""
        import time as t
        start = t.perf_counter()
        
        print(f"[TIMING] process_user_input called with: '{text}'")
        self.emit_log(f"Processing user input: '{text}'", 'info')
        
        command = self.is_command(text)
        if command:
            print(f"[TIMING] Executing command: {command}")
            self.emit_log(f"Executing command: {command}", 'info')
            response = self.execute_command(command)
        else:
            print(f"[TIMING] Calling streaming LLM...")
            self.emit_log("Generating LLM response (streaming)", 'info')
            
            # Define callback to emit tokens to web interface
            def token_callback(token):
                socketio.emit('llm_token', {'token': token})
            
nickspi5@raspberrypi:~ $ 

I also noticed the command translation says 'Fush the toilet' instead of 'Flush the toilet.

This maybe because we are currently using faster-whisper 'tiny' instead of faster-whisper 'base'.

I found previously the translations from faster-whisper 'base' were much more accurate.

So, possibly the Chatty AI service did not consider 'Fush the toilet' to be a command.


















Thank you, Claude,

I ran: nickspi5@raspberrypi:~ $ sudo nano /home/nickspi5/Chatty_AI/chatty_ai.py

I then modified my chatty_ai.py Python script with the following code as you recommended:

            result = self.llama_model(
                formatted_prompt, 
                max_tokens=75,
                stop=["\n", "\n\n", "User:", "Human:", "Assistant:"]
            )

I then found and verified the following code in my chatty_ai.py Python script as you recommended:

                sentences = reply_text.split('.')
                if len(sentences) > 3:
                    reply_text = '. '.join(sentences[:3]) + '.'

I then ran: nickspi5@raspberrypi:~ $ sudo systemctl restart chatty-ai.service
nickspi5@raspberrypi:~ $ sudo reboot

After my Raspberry Pi 5 restarted, I then ran: nickspi5@raspberrypi:~ $ journalctl -u chatty-ai.service --since "30 minutes ago" --no-pager | grep -i "timing\|llm\|generat\|process_user\|inference"
Dec 27 12:56:57 raspberrypi python[1105]: [12:56:57 PM] Warming up LLM...
Dec 27 12:56:58 raspberrypi python[1105]: [12:56:58 PM] LLM warm-up complete
Dec 27 13:00:37 raspberrypi python[1105]: [TIMING] process_user_input called with: 'What is the longest road in the world?'
Dec 27 13:00:37 raspberrypi python[1105]: [TIMING] Calling LLM...
Dec 27 13:00:37 raspberrypi python[1105]: [01:00:37 PM] Generating LLM response
Dec 27 13:00:37 raspberrypi python[1105]: [TIMING] query_llama called with prompt: 'What is the longest road in the world?...'
Dec 27 13:00:37 raspberrypi python[1105]: [TIMING] Starting LLM inference...
Dec 27 13:00:41 raspberrypi python[1105]: [TIMING] LLM inference completed in 3.87s
Dec 27 13:00:41 raspberrypi python[1105]: [TIMING] query_llama total time: 3.87s, response: '41,105 miles or 68,000 kilometers....'
Dec 27 13:00:41 raspberrypi python[1105]: [TIMING] process_user_input total time: 3.87s
Dec 27 13:01:09 raspberrypi python[1105]: [TIMING] process_user_input called with: 'What is the longest river in the world?'
Dec 27 13:01:09 raspberrypi python[1105]: [TIMING] Calling LLM...
Dec 27 13:01:09 raspberrypi python[1105]: [01:01:09 PM] Generating LLM response
Dec 27 13:01:09 raspberrypi python[1105]: [TIMING] query_llama called with prompt: 'What is the longest river in the world?...'
Dec 27 13:01:09 raspberrypi python[1105]: [TIMING] Starting LLM inference...
Dec 27 13:01:12 raspberrypi python[1105]: [TIMING] LLM inference completed in 2.49s
Dec 27 13:01:12 raspberrypi python[1105]: [TIMING] query_llama total time: 2.49s, response: '1.  The Nile River.  It is the longest river in th...'
Dec 27 13:01:12 raspberrypi python[1105]: [TIMING] process_user_input total time: 2.49s
Dec 27 13:01:40 raspberrypi python[1105]: [TIMING] process_user_input called with: 'What is the deepest ocean in the world?'
Dec 27 13:01:40 raspberrypi python[1105]: [TIMING] Calling LLM...
Dec 27 13:01:40 raspberrypi python[1105]: [01:01:40 PM] Generating LLM response
Dec 27 13:01:40 raspberrypi python[1105]: [TIMING] query_llama called with prompt: 'What is the deepest ocean in the world?...'
Dec 27 13:01:40 raspberrypi python[1105]: [TIMING] Starting LLM inference...
Dec 27 13:01:46 raspberrypi python[1105]: [TIMING] LLM inference completed in 5.58s
Dec 27 13:01:46 raspberrypi python[1105]: [TIMING] query_llama total time: 5.58s, response: '150 meters below the ocean surface, located at the...'
Dec 27 13:01:46 raspberrypi python[1105]: [TIMING] process_user_input total time: 5.58s
Dec 27 13:02:20 raspberrypi python[1105]: [TIMING] process_user_input called with: 'Who is sponsoring this video?'
Dec 27 13:02:20 raspberrypi python[1105]: [TIMING] Executing command: who is sponsoring this video
Dec 27 13:02:22 raspberrypi python[1105]: [TIMING] process_user_input total time: 1.63s
nickspi5@raspberrypi:~ $ 











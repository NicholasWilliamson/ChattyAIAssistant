


The issue is that we're doing two transcriptions: one during streaming (partial) and then another full transcription at the end. This is redundant and causes the delay.
Let's fix this by reusing the partial transcript instead of transcribing again:
bashnano /home/nickspi5/Chatty_AI/chatty_ai.py
Find the section in listen_for_wake_word that looks like this (around line 1135-1150):
python                            # Record full request with streaming transcription
                            self.emit_log("Please speak your request...", 'info')
                            if self.record_with_streaming_transcription():
                                user_text = self.transcribe_audio(WAV_FILENAME)
Change it to skip the redundant transcription:
python                            # Record full request with streaming transcription
                            self.emit_log("Please speak your request...", 'info')
                            if self.record_with_streaming_transcription():
                                # Final transcription on saved audio (more accurate)
                                user_text = self.transcribe_audio(WAV_FILENAME)
Actually wait - we need to look at this more carefully. The issue is that we're always doing a final transcription even though we already have partial transcripts. Let me check what the function returns:
bashgrep -A5 "return True" /home/nickspi5/Chatty_AI/chatty_ai.py | grep -A5 "record_with_streaming"
Let's modify the function to return the transcript directly instead of just True/False. First, show me the end of the function:
bashsed -n '900,950p' /home/nickspi5/Chatty_AI/chatty_ai.py
This will help me see how to optimize so we don't need to transcribe twice.





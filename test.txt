
Thank you, Claude,

I ran: nickspi5@raspberrypi:~ $ sudo systemctl restart chatty-ai.service
nickspi5@raspberrypi:~ $ cd /home/nickspi5/Chatty_AI
nickspi5@raspberrypi:~/Chatty_AI $ source chatty-venv/bin/activate
(chatty-venv) nickspi5@raspberrypi:~/Chatty_AI $ python3 performance_test.py

============================================================
  CHATTY AI PERFORMANCE BENCHMARK
============================================================

System: aarch64
Python: 3.13.5
RAM: 15.8 GB
CPU Cores: 4

Hailo AI HAT Status:
  [OK] Hailo AI HAT is working
    Firmware Version: 4.23.0 (release,app,extended context switch buffer)
    Device Architecture: HAILO8L
    Product Name: HAILO-8L AI ACC M.2 B+M KEY MODULE EXT TMP

[1/5] Testing Faster-Whisper Model Loading...

==================================================
Benchmarking: Faster-Whisper Load
==================================================
  Run 1: 1.201s
  Average: 1.201s
  Min: 1.201s | Max: 1.201s

[2/5] Testing Speech-to-Text (Faster-Whisper)...
  Using: /home/nickspi5/Chatty_AI/test_audio.wav

==================================================
Benchmarking: STT Transcription
==================================================
  Run 1: 1.659s
  Run 2: 1.727s
  Run 3: 1.715s
  Average: 1.700s
  Min: 1.659s | Max: 1.727s

[3/5] Testing LLaMA Model Loading...

==================================================
Benchmarking: LLaMA Load
==================================================
llama_context: n_ctx_per_seq (512) < n_ctx_train (2048) -- the full capacity of the model will not be utilized
  Run 1: 0.142s
  Average: 0.142s
  Min: 0.142s | Max: 0.142s
llama_context: n_ctx_per_seq (512) < n_ctx_train (2048) -- the full capacity of the model will not be utilized

[4/5] Testing LLM Inference...

==================================================
Benchmarking: LLM Inference
==================================================
  Run 1: 3.170s
  Run 2: 0.461s
  Run 3: 0.082s
  Average: 1.238s
  Min: 0.082s | Max: 3.170s

[5/5] Testing Text-to-Speech (Piper)...

==================================================
Benchmarking: TTS Generation
==================================================
  Run 1: 0.747s
  Run 2: 0.750s
  Run 3: 0.776s
  Average: 0.758s
  Min: 0.747s | Max: 0.776s

============================================================
  PERFORMANCE SUMMARY
============================================================

Component                 Time (seconds)  Status
-------------------------------------------------------
whisper_load              1.201           [OK]
stt                       1.700           [OK]
llama_load                0.142           [OK]
llm                       1.238           [OK]
tts                       0.758           [OK]

-------------------------------------------------------
Estimated Response Time   3.696          

============================================================
  RECOMMENDATIONS
============================================================

- To use Hailo AI HAT acceleration, models need to be
  converted to HEF format (Hailo Executable Format)

Done!
(chatty-venv) nickspi5@raspberrypi:~/Chatty_AI $ 

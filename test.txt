Thank you Claude.

I have my Python script function test_chatty_ai.py to 3. Test Transcription (for fine-tuning wake words) and for 1. Wake Word Detection (continuous listening):

test_chatty_ai.py
#!/usr/bin/env python3
"""
test_chatty_ai.py - Enhanced with Wake Word Detection
Record voice, transcribe using Whisper, reply with TinyLLaMA, and speak with Piper.
Includes wake word detection, silence detection, and command vs question processing.
"""

import os
import subprocess
import sounddevice as sd
import soundfile as sf
import numpy as np
import threading
import time
import random
import re
from faster_whisper import WhisperModel
from llama_cpp import Llama

# -------------------------------
# Config
# -------------------------------
WHISPER_MODEL_SIZE = "base"
LLAMA_MODEL_PATH = "tinyllama-models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf"
VOICE_PATH = "/home/nickspi5/Chatty_AI/voices/en_US-amy-low/en_US-amy-low.onnx"
CONFIG_PATH = "/home/nickspi5/Chatty_AI/voices/en_US-amy-low/en_US-amy-low.onnx.json"
PIPER_EXECUTABLE = "/home/nickspi5/Chatty_AI/piper/piper"
BEEP_SOUND = "/home/nickspi5/Chatty_AI/audio_files/beep.wav"
WAV_FILENAME = "user_input.wav"
RESPONSE_AUDIO = "output.wav"
WAKE_WORD_AUDIO = "wake_word_check.wav"

# Wake word phrases (case insensitive)
WAKE_WORDS = [
    "hey chatty",
    "hello chatty", 
    "sup chatty",
    "howzit chatty",
    "hi chatty",
    "yo chatty",
    "Hello, Chuddy",
    "sub-cherry",
    "How's it cherry",
    "Hey Cherry"
]

# Wake word acknowledgment responses
WAKE_RESPONSES = [
    "Hi, I am listening for your request",
    "Hello! What can I help you with?",
    "Yes, I'm here. What do you need?",
    "Hi there! I'm ready to assist you",
    "Hello! How can I help you today?",
    "I'm listening. What's your question?",
    "Yes? What would you like to know?",
    "Hi! What can I do for you?"
]

# Command keywords and their functions
COMMANDS = {
    "flush the toilet": "toilet_flush",
    "turn on the lights": "lights_on", 
    "turn off the lights": "lights_off",
    "play music": "play_music",
    "stop music": "stop_music",
    "what time is it": "get_time",
    "shutdown system": "shutdown_system",
    "reboot system": "reboot_system"
}

# Audio recording parameters
SAMPLE_RATE = 16000
CHANNELS = 1
CHUNK_DURATION = 0.1  # 100ms chunks
SILENCE_THRESHOLD = 0.01  # Adjust based on your environment
MIN_SILENCE_DURATION = 1.5  # 1.5 seconds of silence to stop recording
MAX_RECORDING_DURATION = 30  # Maximum 30 seconds per recording

class ChattyAI:
    def __init__(self):
        self.whisper_model = None
        self.llama_model = None
        self.is_listening = False
        self.is_recording = False
        self.audio_buffer = []
        self.load_models()
    
    def load_models(self):
        """Load Whisper and LLaMA models"""
        print("ğŸ”„ Loading AI models...")
        try:
            self.whisper_model = WhisperModel(WHISPER_MODEL_SIZE, device="cpu", compute_type="int8")
            print("âœ… Whisper model loaded")
        except Exception as e:
            print(f"âŒ Failed to load Whisper: {e}")
            return False
        
        try:
            self.llama_model = Llama(
                model_path=LLAMA_MODEL_PATH, 
                n_ctx=2048, 
                temperature=0.7, 
                repeat_penalty=1.1, 
                n_gpu_layers=0, 
                verbose=False
            )
            print("âœ… LLaMA model loaded")
        except Exception as e:
            print(f"âŒ Failed to load LLaMA: {e}")
            return False
        
        return True
    
    def play_beep(self):
        """Play beep sound to acknowledge wake word"""
        try:
            subprocess.run(["aplay", BEEP_SOUND], check=True, capture_output=True)
        except subprocess.CalledProcessError:
            print("âŒ Could not play beep sound")
        except FileNotFoundError:
            print(f"âŒ Beep file not found: {BEEP_SOUND}")
    
    def speak_text(self, text):
        """Convert text to speech using Piper"""
        print(f"ğŸ”Š Speaking: {text}")
        try:
            command = [
                PIPER_EXECUTABLE,
                "--model", VOICE_PATH,
                "--config", CONFIG_PATH,
                "--output_file", RESPONSE_AUDIO
            ]
            subprocess.run(command, input=text.encode("utf-8"), check=True, capture_output=True)
            subprocess.run(["aplay", RESPONSE_AUDIO], check=True, capture_output=True)
        except subprocess.CalledProcessError as e:
            print(f"âŒ TTS failed: {e}")
    
    def transcribe_audio(self, filename):
        """Transcribe audio using Whisper"""
        try:
            segments, _ = self.whisper_model.transcribe(filename)
            transcript = " ".join(segment.text for segment in segments).strip()
            return transcript
        except Exception as e:
            print(f"âŒ Transcription failed: {e}")
            return ""
    
    def detect_wake_word(self, text):
        """Check if text contains any wake word"""
        text_lower = text.lower().strip()
        for wake_word in WAKE_WORDS:
            if wake_word in text_lower:
                print(f"ğŸ¯ Wake word detected: '{wake_word}' in '{text}'")
                return True
        return False
    
    def is_silence(self, audio_chunk):
        """Detect if audio chunk is silence"""
        rms = np.sqrt(np.mean(audio_chunk**2))
        return rms < SILENCE_THRESHOLD
    
    def record_with_silence_detection(self):
        """Record audio until silence is detected"""
        print("ğŸ¤ Recording... (speak now, I'll stop when you're quiet)")
        
        audio_data = []
        silence_duration = 0
        recording_duration = 0
        
        def audio_callback(indata, frames, time, status):
            if status:
                print(f"Audio status: {status}")
            audio_data.extend(indata[:, 0])  # Take first channel
        
        # Start recording
        with sd.InputStream(callback=audio_callback, 
                          samplerate=SAMPLE_RATE, 
                          channels=CHANNELS,
                          dtype='float32'):
            
            while recording_duration < MAX_RECORDING_DURATION:
                time.sleep(CHUNK_DURATION)
                recording_duration += CHUNK_DURATION
                
                # Check for silence in recent audio
                if len(audio_data) > int(SAMPLE_RATE * CHUNK_DURATION):
                    recent_audio = np.array(audio_data[-int(SAMPLE_RATE * CHUNK_DURATION):])
                    
                    if self.is_silence(recent_audio):
                        silence_duration += CHUNK_DURATION
                        if silence_duration >= MIN_SILENCE_DURATION:
                            print("ğŸ”‡ Silence detected, stopping recording")
                            break
                    else:
                        silence_duration = 0  # Reset silence counter
        
        # Save recorded audio
        if audio_data:
            audio_array = np.array(audio_data, dtype=np.float32)
            sf.write(WAV_FILENAME, audio_array, SAMPLE_RATE)
            print(f"âœ… Recorded {len(audio_array)/SAMPLE_RATE:.1f} seconds of audio")
            return True
        
        return False
    
    def is_command(self, text):
        """Check if text is a command"""
        text_lower = text.lower().strip()
        for command in COMMANDS.keys():
            if command in text_lower:
                return command
        return None
    
    def execute_command(self, command):
        """Execute a system command"""
        command_func = COMMANDS.get(command)
        
        if command == "flush the toilet":
            response = "I'm a digital assistant - I can't actually flush toilets! But I'd be happy to help with other tasks."
        elif command == "turn on the lights":
            response = "I would turn on the lights if I were connected to a smart home system."
        elif command == "turn off the lights":
            response = "I would turn off the lights if I were connected to a smart home system."
        elif command == "play music":
            response = "I would start playing music if I had access to a music system."
        elif command == "stop music":
            response = "I would stop the music if any was playing."
        elif command == "what time is it":
            import datetime
            current_time = datetime.datetime.now().strftime("%I:%M %p")
            response = f"The current time is {current_time}"
        elif command == "shutdown system":
            response = "I would shutdown the system, but I'll skip that for safety during testing."
        elif command == "reboot system":
            response = "I would reboot the system, but I'll skip that for safety during testing."
        else:
            response = f"I understand you want me to {command}, but I don't have that capability yet."
        
        return response
    
    def query_llama(self, prompt):
        """Generate LLM response for questions"""
        print("ğŸ¤– Generating LLM response...")
        
        formatted_prompt = f"You are a friendly, helpful assistant. Give a brief, conversational answer.\nUser: {prompt}\nAssistant: "
        
        try:
            result = self.llama_model(formatted_prompt, max_tokens=100)
            if "choices" in result and result["choices"]:
                reply_text = result["choices"][0]["text"].strip()
                # Clean up the response
                reply_text = re.sub(r"\(.*?\)", "", reply_text)  # Remove roleplay
                reply_text = re.sub(r"(User:|Assistant:)", "", reply_text)  # Remove labels
                reply_text = reply_text.strip()
                
                # Ensure response isn't too long
                sentences = reply_text.split('.')
                if len(sentences) > 3:
                    reply_text = '. '.join(sentences[:3]) + '.'
                
                return reply_text
            else:
                return "I'm not sure how to answer that."
        except Exception as e:
            print(f"âŒ LLM inference failed: {e}")
            return "Sorry, I had trouble processing that question."
    
    def process_user_input(self, text):
        """Process user input - determine if command or question"""
        print(f"ğŸ“ Processing: {text}")
        
        # Check if it's a command
        command = self.is_command(text)
        if command:
            print(f"âš™ï¸ Executing command: {command}")
            response = self.execute_command(command)
        else:
            print("â“ Processing as question for LLM")
            response = self.query_llama(text)
        
        return response
    
    def listen_for_wake_word(self):
        """Continuously listen for wake words"""
        print("ğŸ‘‚ Listening for wake words...")
        print(f"Wake words: {', '.join(WAKE_WORDS)}")
        
        while self.is_listening:
            try:
                # Record a short clip to check for wake word
                print("ğŸ” Checking for wake word...")
                audio = sd.rec(int(3 * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=CHANNELS, dtype='int16')
                sd.wait()
                sf.write(WAKE_WORD_AUDIO, audio, SAMPLE_RATE)
                
                # Transcribe and check for wake word
                transcript = self.transcribe_audio(WAKE_WORD_AUDIO)
                
                if transcript and self.detect_wake_word(transcript):
                    # Wake word detected!
                    self.play_beep()
                    
                    # Speak acknowledgment
                    response = random.choice(WAKE_RESPONSES)
                    self.speak_text(response)
                    
                    # Record user's full request
                    if self.record_with_silence_detection():
                        user_text = self.transcribe_audio(WAV_FILENAME)
                        if user_text:
                            print(f"ğŸ‘¤ User said: {user_text}")
                            
                            # Process the input
                            ai_response = self.process_user_input(user_text)
                            self.speak_text(ai_response)
                        else:
                            self.speak_text("I didn't catch that. Could you try again?")
                    
                    print("ğŸ‘‚ Back to listening for wake words...")
                
                time.sleep(0.5)  # Brief pause between checks
                
            except KeyboardInterrupt:
                print("\nğŸ›‘ Stopping wake word detection...")
                break
            except Exception as e:
                print(f"âŒ Error in wake word detection: {e}")
                time.sleep(1)
    
    def test_transcription(self):
        """Test function to check transcription accuracy"""
        print("ğŸ§ª TRANSCRIPTION TEST MODE")
        print("Speak phrases to test wake word detection accuracy")
        print("Press Ctrl+C to exit test mode")
        
        while True:
            try:
                input("Press Enter to record a test phrase...")
                
                # Record 3 seconds
                print("ğŸ¤ Recording test phrase...")
                audio = sd.rec(int(3 * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=CHANNELS, dtype='int16')
                sd.wait()
                sf.write("test_audio.wav", audio, SAMPLE_RATE)
                
                # Transcribe
                transcript = self.transcribe_audio("test_audio.wav")
                print(f"ğŸ“ I heard: '{transcript}'")
                
                # Check wake word detection
                if self.detect_wake_word(transcript):
                    print("âœ… WAKE WORD DETECTED!")
                else:
                    print("âŒ No wake word detected")
                
                print("-" * 50)
                
            except KeyboardInterrupt:
                print("\nğŸ›‘ Exiting test mode")
                break
    
    def start_listening(self):
        """Start the wake word detection system"""
        if not self.whisper_model or not self.llama_model:
            print("âŒ Models not loaded properly")
            return
        
        self.is_listening = True
        
        print("ğŸš€ Chatty AI Wake Word Detection Started!")
        print("=" * 50)
        print("Say one of these wake words to activate:")
        for wake_word in WAKE_WORDS:
            print(f"  â€¢ {wake_word}")
        print("=" * 50)
        
        try:
            self.listen_for_wake_word()
        except KeyboardInterrupt:
            print("\nğŸ›‘ Shutting down Chatty AI...")
        finally:
            self.is_listening = False
    
    def run_single_interaction(self):
        """Run the original single-interaction mode"""
        print("ğŸ¤ Single interaction mode - Recording 5 seconds...")
        
        # Record audio
        audio = sd.rec(int(5 * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=CHANNELS, dtype='int16')
        sd.wait()
        sf.write(WAV_FILENAME, audio, SAMPLE_RATE)
        
        # Transcribe
        user_text = self.transcribe_audio(WAV_FILENAME)
        if not user_text:
            print("âŒ No voice input detected.")
            return
        
        print(f"ğŸ‘¤ You said: {user_text}")
        
        # Process and respond
        response = self.process_user_input(user_text)
        self.speak_text(response)

def main():
    """Main function with mode selection"""
    chatty = ChattyAI()
    
    print("ğŸ¤– Chatty AI - Enhanced with Wake Word Detection")
    print("=" * 60)
    print("Choose mode:")
    print("1. Wake Word Detection (continuous listening)")
    print("2. Single Interaction (original 5-second recording)")
    print("3. Test Transcription (for fine-tuning wake words)")
    print("=" * 60)
    
    try:
        choice = input("Enter your choice (1/2/3): ").strip()
        
        if choice == "1":
            chatty.start_listening()
        elif choice == "2":
            chatty.run_single_interaction()
        elif choice == "3":
            chatty.test_transcription()
        else:
            print("âŒ Invalid choice. Exiting.")
    
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Goodbye!")

if __name__ == "__main__":
    main()

I ran: nickspi5@raspberrypi1:~ $ cd Chatty_AI
nickspi5@raspberrypi1:~/Chatty_AI $ source chatty-venv/bin/activate
(chatty-venv) nickspi5@raspberrypi1:~/Chatty_AI $ python3 test_chatty_ai.py
ğŸ”„ Loading AI models...
âœ… Whisper model loaded
llama_kv_cache_unified: LLAMA_SET_ROWS=0, using old ggml_cpy() method for backwards compatibility
âœ… LLaMA model loaded
ğŸ¤– Chatty AI - Enhanced with Wake Word Detection
============================================================
Choose mode:
1. Wake Word Detection (continuous listening)
2. Single Interaction (original 5-second recording)
3. Test Transcription (for fine-tuning wake words)
============================================================
Enter your choice (1/2/3): 3
ğŸ§ª TRANSCRIPTION TEST MODE
Speak phrases to test wake word detection accuracy
Press Ctrl+C to exit test mode
Press Enter to record a test phrase...
ğŸ¤ Recording test phrase...
ğŸ“ I heard: 'Hello, Cheri.'
âŒ No wake word detected
--------------------------------------------------
Press Enter to record a test phrase...
ğŸ¤ Recording test phrase...
ğŸ“ I heard: 'Hello, Chetty.'
âŒ No wake word detected
--------------------------------------------------
Press Enter to record a test phrase...
ğŸ¤ Recording test phrase...
ğŸ“ I heard: 'Hi, Cherry.'
âŒ No wake word detected
--------------------------------------------------
Press Enter to record a test phrase...
ğŸ¤ Recording test phrase...
ğŸ“ I heard: 'Soft cherry'
âŒ No wake word detected
--------------------------------------------------
Press Enter to record a test phrase...
ğŸ¤ Recording test phrase...
ğŸ“ I heard: 'How's it Chetty?'
âŒ No wake word detected
--------------------------------------------------
Press Enter to record a test phrase...
ğŸ¤ Recording test phrase...
ğŸ“ I heard: 'Hello, Cherry.'
âŒ No wake word detected
--------------------------------------------------
Press Enter to record a test phrase...
ğŸ¤ Recording test phrase...
ğŸ“ I heard: 'Hello chatty'
ğŸ¯ Wake word detected: 'hello chatty' in 'Hello chatty'
âœ… WAKE WORD DETECTED!
--------------------------------------------------
Press Enter to record a test phrase...
ğŸ¤ Recording test phrase...
ğŸ“ I heard: 'Hey Chetty!'
âŒ No wake word detected
--------------------------------------------------
Press Enter to record a test phrase...^C
ğŸ›‘ Exiting test mode
(chatty-venv) nickspi5@raspberrypi1:~/Chatty_AI $ python3 test_chatty_ai.py
ğŸ”„ Loading AI models...
âœ… Whisper model loaded
llama_kv_cache_unified: LLAMA_SET_ROWS=0, using old ggml_cpy() method for backwards compatibility
âœ… LLaMA model loaded
ğŸ¤– Chatty AI - Enhanced with Wake Word Detection
============================================================
Choose mode:
1. Wake Word Detection (continuous listening)
2. Single Interaction (original 5-second recording)
3. Test Transcription (for fine-tuning wake words)
============================================================
Enter your choice (1/2/3): 1
ğŸš€ Chatty AI Wake Word Detection Started!
==================================================
Say one of these wake words to activate:
  â€¢ hey chatty
  â€¢ hello chatty
  â€¢ sup chatty
  â€¢ howzit chatty
  â€¢ hi chatty
  â€¢ yo chatty
  â€¢ Hello, Chuddy
  â€¢ sub-cherry
  â€¢ How's it cherry
  â€¢ Hey Cherry
==================================================
ğŸ‘‚ Listening for wake words...
Wake words: hey chatty, hello chatty, sup chatty, howzit chatty, hi chatty, yo chatty, Hello, Chuddy, sub-cherry, How's it cherry, Hey Cherry
ğŸ” Checking for wake word...
ğŸ” Checking for wake word...
ğŸ” Checking for wake word...
ğŸ” Checking for wake word...
^C
ğŸ›‘ Stopping wake word detection...
(chatty-venv) nickspi5@raspberrypi1:~/Chatty_AI $ 

The function to 3. Test Transcription works perfectly.

The function for 1. Wake Word Detection does not seem to be working at all.

I would like this to be fixed immediately so that I can finish off this function.

I would also like the 1. Wake Word Detection to print out what it has recorded for debugging purposes as well.

Please fix my Python script.



